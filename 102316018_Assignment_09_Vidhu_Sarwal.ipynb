{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "17c2ede3-313f-4488-8065-553006a1efa6",
      "metadata": {
        "id": "17c2ede3-313f-4488-8065-553006a1efa6"
      },
      "source": [
        "# Question 1\n",
        "### Write a unique paragraph (5-6 sentences) about your favorite topic (e.g., sports, technology, food, books, etc.).\n",
        "1. Convert text to lowercase and remove punctuaƟon.\n",
        "2. Tokenize the text into words and sentences.\n",
        "3. Remove stopwords (using NLTK's stopwords list).\n",
        "4. Display word frequency distribuƟon (excluding stopwords)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "6fe0056b-d290-4f14-bb39-9684e86fdda3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6fe0056b-d290-4f14-bb39-9684e86fdda3",
        "outputId": "121470fb-1d82-4338-edc5-01d16ea68e87"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.1.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk) (4.67.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install nltk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "ab118907-6830-4a80-b3b5-db101ec4f2c2",
      "metadata": {
        "id": "ab118907-6830-4a80-b3b5-db101ec4f2c2"
      },
      "outputs": [],
      "source": [
        "sentence = \"\"\"\n",
        "Among all my interests, technology captivates me the most—especially how it's reshaping human interaction and creativity.\n",
        "The rise of AI has transformed the way we write, code, and even imagine the future, blurring the lines between human and machine.\n",
        "I find the development of edge computing particularly fascinating, as it enables real-time data processing right where it’s generated, reducing latency and empowering smarter IoT systems.\n",
        "Every new hardware breakthrough, like RISC-V processors or neuromorphic chips, feels like a small step closer to mimicking human cognition.\n",
        "What excites me most is the potential for democratizing innovation, giving even small creators the tools once reserved for large corporations.\n",
        "It's a thrilling time to be alive—where imagination quickly becomes prototype, and ideas can spark global change.\n",
        "\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "b3cd1155-77b3-41d6-902e-b4513ec1950a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b3cd1155-77b3-41d6-902e-b4513ec1950a",
        "outputId": "4cd66eaf-e3e0-435a-9b1c-7ca54ce44b79"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "among all my interests technology captivates me the most—especially how its reshaping human interaction and creativity \n",
            "the rise of ai has transformed the way we write code and even imagine the future blurring the lines between human and machine \n",
            "i find the development of edge computing particularly fascinating as it enables realtime data processing right where it’s generated reducing latency and empowering smarter iot systems \n",
            "every new hardware breakthrough like riscv processors or neuromorphic chips feels like a small step closer to mimicking human cognition \n",
            "what excites me most is the potential for democratizing innovation giving even small creators the tools once reserved for large corporations \n",
            "its a thrilling time to be alive—where imagination quickly becomes prototype and ideas can spark global change\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import string\n",
        "text_low = sentence.lower()\n",
        "no_punc = text_low.translate(str.maketrans('', '', string.punctuation))\n",
        "print(no_punc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "8e71e258-fca7-45b3-8601-f8a994fc4ec8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8e71e258-fca7-45b3-8601-f8a994fc4ec8",
        "outputId": "88dc209f-198f-4138-8be5-6299c8cf20e8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "2519cfc0-eacc-430e-bff6-12762151e505",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2519cfc0-eacc-430e-bff6-12762151e505",
        "outputId": "53fe3c4f-a777-440f-8a37-2c7fd72cef55"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenized words:   ['among', 'all', 'my', 'interests', 'technology', 'captivates', 'me', 'the', 'most—especially', 'how', 'its', 'reshaping', 'human', 'interaction', 'and', 'creativity', 'the', 'rise', 'of', 'ai', 'has', 'transformed', 'the', 'way', 'we', 'write', 'code', 'and', 'even', 'imagine', 'the', 'future', 'blurring', 'the', 'lines', 'between', 'human', 'and', 'machine', 'i', 'find', 'the', 'development', 'of', 'edge', 'computing', 'particularly', 'fascinating', 'as', 'it', 'enables', 'realtime', 'data', 'processing', 'right', 'where', 'it', '’', 's', 'generated', 'reducing', 'latency', 'and', 'empowering', 'smarter', 'iot', 'systems', 'every', 'new', 'hardware', 'breakthrough', 'like', 'riscv', 'processors', 'or', 'neuromorphic', 'chips', 'feels', 'like', 'a', 'small', 'step', 'closer', 'to', 'mimicking', 'human', 'cognition', 'what', 'excites', 'me', 'most', 'is', 'the', 'potential', 'for', 'democratizing', 'innovation', 'giving', 'even', 'small', 'creators', 'the', 'tools', 'once', 'reserved', 'for', 'large', 'corporations', 'its', 'a', 'thrilling', 'time', 'to', 'be', 'alive—where', 'imagination', 'quickly', 'becomes', 'prototype', 'and', 'ideas', 'can', 'spark', 'global', 'change'] \n",
            "\n",
            "Tokenized Sentences:   [\"\\nAmong all my interests, technology captivates me the most—especially how it's reshaping human interaction and creativity.\", 'The rise of AI has transformed the way we write, code, and even imagine the future, blurring the lines between human and machine.', 'I find the development of edge computing particularly fascinating, as it enables real-time data processing right where it’s generated, reducing latency and empowering smarter IoT systems.', 'Every new hardware breakthrough, like RISC-V processors or neuromorphic chips, feels like a small step closer to mimicking human cognition.', 'What excites me most is the potential for democratizing innovation, giving even small creators the tools once reserved for large corporations.', \"It's a thrilling time to be alive—where imagination quickly becomes prototype, and ideas can spark global change.\"] \n",
            "\n"
          ]
        }
      ],
      "source": [
        "words = word_tokenize(no_punc)\n",
        "sent = sent_tokenize(sentence)\n",
        "print(\"Tokenized words:  \", words,\"\\n\")\n",
        "print(\"Tokenized Sentences:  \", sent,\"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "35b03bed-d826-4e1b-8b09-6bc742c95667",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "35b03bed-d826-4e1b-8b09-6bc742c95667",
        "outputId": "cd8c7c5f-7755-439e-9b14-201c1c25639c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ],
      "source": [
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "stopper = set(stopwords.words('english'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "16f21f29-e0f5-425b-ad6b-97feb0757d0e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "16f21f29-e0f5-425b-ad6b-97feb0757d0e",
        "outputId": "1df5c86a-ac48-41bb-8d41-a21c055efea5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Filtered Word Tokens:\n",
            " ['among', 'interests', 'technology', 'captivates', 'most—especially', 'reshaping', 'human', 'interaction', 'creativity', 'rise', 'ai', 'transformed', 'way', 'write', 'code', 'even', 'imagine', 'future', 'blurring', 'lines', 'human', 'machine', 'find', 'development', 'edge', 'computing', 'particularly', 'fascinating', 'enables', 'realtime', 'data', 'processing', 'right', '’', 'generated', 'reducing', 'latency', 'empowering', 'smarter', 'iot', 'systems', 'every', 'new', 'hardware', 'breakthrough', 'like', 'riscv', 'processors', 'neuromorphic', 'chips', 'feels', 'like', 'small', 'step', 'closer', 'mimicking', 'human', 'cognition', 'excites', 'potential', 'democratizing', 'innovation', 'giving', 'even', 'small', 'creators', 'tools', 'reserved', 'large', 'corporations', 'thrilling', 'time', 'alive—where', 'imagination', 'quickly', 'becomes', 'prototype', 'ideas', 'spark', 'global', 'change'] \n",
            "\n"
          ]
        }
      ],
      "source": [
        "stopper_removed = [w for w in words if w not in stopper]\n",
        "print(\"Filtered Word Tokens:\\n\", stopper_removed ,'\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "04b7aa6f-0141-43ef-8c21-ac3fe7a8e75f",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "04b7aa6f-0141-43ef-8c21-ac3fe7a8e75f",
        "outputId": "00781fe2-930f-448a-ea52-91cbbe324c38"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Word Frequency Distribution:\n",
            "among: 1\n",
            "interests: 1\n",
            "technology: 1\n",
            "captivates: 1\n",
            "most—especially: 1\n",
            "reshaping: 1\n",
            "human: 3\n",
            "interaction: 1\n",
            "creativity: 1\n",
            "rise: 1\n",
            "ai: 1\n",
            "transformed: 1\n",
            "way: 1\n",
            "write: 1\n",
            "code: 1\n",
            "even: 2\n",
            "imagine: 1\n",
            "future: 1\n",
            "blurring: 1\n",
            "lines: 1\n",
            "machine: 1\n",
            "find: 1\n",
            "development: 1\n",
            "edge: 1\n",
            "computing: 1\n",
            "particularly: 1\n",
            "fascinating: 1\n",
            "enables: 1\n",
            "realtime: 1\n",
            "data: 1\n",
            "processing: 1\n",
            "right: 1\n",
            "’: 1\n",
            "generated: 1\n",
            "reducing: 1\n",
            "latency: 1\n",
            "empowering: 1\n",
            "smarter: 1\n",
            "iot: 1\n",
            "systems: 1\n",
            "every: 1\n",
            "new: 1\n",
            "hardware: 1\n",
            "breakthrough: 1\n",
            "like: 2\n",
            "riscv: 1\n",
            "processors: 1\n",
            "neuromorphic: 1\n",
            "chips: 1\n",
            "feels: 1\n",
            "small: 2\n",
            "step: 1\n",
            "closer: 1\n",
            "mimicking: 1\n",
            "cognition: 1\n",
            "excites: 1\n",
            "potential: 1\n",
            "democratizing: 1\n",
            "innovation: 1\n",
            "giving: 1\n",
            "creators: 1\n",
            "tools: 1\n",
            "reserved: 1\n",
            "large: 1\n",
            "corporations: 1\n",
            "thrilling: 1\n",
            "time: 1\n",
            "alive—where: 1\n",
            "imagination: 1\n",
            "quickly: 1\n",
            "becomes: 1\n",
            "prototype: 1\n",
            "ideas: 1\n",
            "spark: 1\n",
            "global: 1\n",
            "change: 1\n"
          ]
        }
      ],
      "source": [
        "from nltk.probability import FreqDist\n",
        "frequency_dist = FreqDist(stopper_removed)\n",
        "print(\"\\nWord Frequency Distribution:\")\n",
        "for word, frequency in frequency_dist.items():\n",
        "    print(f\"{word}: {frequency}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "910039f1-ab9c-4a29-8c5a-8c3f1a488b4c",
      "metadata": {
        "id": "910039f1-ab9c-4a29-8c5a-8c3f1a488b4c"
      },
      "source": [
        "# Question 2\n",
        "### Stemming and Lemmatization\n",
        "1. Take the tokenized words from QuesƟon 1 (aŌer stopword removal).\n",
        "2. Apply stemming using NLTK's PorterStemmer and LancasterStemmer.\n",
        "3. Apply lemmaƟzaƟon using NLTK's WordNetLemmaƟzer.\n",
        "4. Compare and display results of both techniques.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "d73d1f7d-bb88-40a6-9eda-13bd1452b3dc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d73d1f7d-bb88-40a6-9eda-13bd1452b3dc",
        "outputId": "78134cbf-5689-46bf-9d3a-10f7b6ebb372"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n"
          ]
        }
      ],
      "source": [
        "from nltk.stem import PorterStemmer, LancasterStemmer, WordNetLemmatizer\n",
        "\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4') #lematizer\n",
        "porter = PorterStemmer()\n",
        "lancaster = LancasterStemmer()\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "portered = [porter.stem(w) for w in stopper_removed]\n",
        "lancastered = [lancaster.stem(w) for w in stopper_removed]\n",
        "lemmatized = [lemmatizer.lemmatize(w) for w in stopper_removed]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "5dcdf1ec-56fc-496e-8efc-491dd2089bab",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5dcdf1ec-56fc-496e-8efc-491dd2089bab",
        "outputId": "ff80e8da-0002-4d02-b717-3ef74a2ea5d2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original            Porter              Lancaster           Lemma              \n",
            "------------------------------------------------------------\n",
            "among               among               among               among              \n",
            "interests           interest            interest            interest           \n",
            "technology          technolog           technolog           technology         \n",
            "captivates          captiv              capt                captivates         \n",
            "most—especially     most—especi         most—especially     most—especially    \n",
            "reshaping           reshap              reshap              reshaping          \n",
            "human               human               hum                 human              \n",
            "interaction         interact            interact            interaction        \n",
            "creativity          creativ             cre                 creativity         \n",
            "rise                rise                ris                 rise               \n",
            "ai                  ai                  ai                  ai                 \n",
            "transformed         transform           transform           transformed        \n",
            "way                 way                 way                 way                \n",
            "write               write               writ                write              \n",
            "code                code                cod                 code               \n",
            "even                even                ev                  even               \n",
            "imagine             imagin              imagin              imagine            \n",
            "future              futur               fut                 future             \n",
            "blurring            blur                blur                blurring           \n",
            "lines               line                lin                 line               \n",
            "human               human               hum                 human              \n",
            "machine             machin              machin              machine            \n",
            "find                find                find                find               \n",
            "development         develop             develop             development        \n",
            "edge                edg                 edg                 edge               \n",
            "computing           comput              comput              computing          \n",
            "particularly        particularli        particul            particularly       \n",
            "fascinating         fascin              fascin              fascinating        \n",
            "enables             enabl               en                  enables            \n",
            "realtime            realtim             realtim             realtime           \n",
            "data                data                dat                 data               \n",
            "processing          process             process             processing         \n",
            "right               right               right               right              \n",
            "’                   ’                   ’                   ’                  \n",
            "generated           gener               gen                 generated          \n",
            "reducing            reduc               reduc               reducing           \n",
            "latency             latenc              lat                 latency            \n",
            "empowering          empow               empow               empowering         \n",
            "smarter             smarter             smart               smarter            \n",
            "iot                 iot                 iot                 iot                \n",
            "systems             system              system              system             \n",
            "every               everi               every               every              \n",
            "new                 new                 new                 new                \n",
            "hardware            hardwar             hardw               hardware           \n",
            "breakthrough        breakthrough        breakthrough        breakthrough       \n",
            "like                like                lik                 like               \n",
            "riscv               riscv               riscv               riscv              \n",
            "processors          processor           process             processor          \n",
            "neuromorphic        neuromorph          neuromorph          neuromorphic       \n",
            "chips               chip                chip                chip               \n",
            "feels               feel                feel                feel               \n",
            "like                like                lik                 like               \n",
            "small               small               smal                small              \n",
            "step                step                step                step               \n",
            "closer              closer              clos                closer             \n",
            "mimicking           mimick              mimick              mimicking          \n",
            "human               human               hum                 human              \n",
            "cognition           cognit              cognit              cognition          \n",
            "excites             excit               excit               excites            \n",
            "potential           potenti             pot                 potential          \n",
            "democratizing       democrat            democr              democratizing      \n",
            "innovation          innov               innov               innovation         \n",
            "giving              give                giv                 giving             \n",
            "even                even                ev                  even               \n",
            "small               small               smal                small              \n",
            "creators            creator             cre                 creator            \n",
            "tools               tool                tool                tool               \n",
            "reserved            reserv              reserv              reserved           \n",
            "large               larg                larg                large              \n",
            "corporations        corpor              corp                corporation        \n",
            "thrilling           thrill              thrilling           thrilling          \n",
            "time                time                tim                 time               \n",
            "alive—where         alive—wher          alive—wher          alive—where        \n",
            "imagination         imagin              imagin              imagination        \n",
            "quickly             quickli             quick               quickly            \n",
            "becomes             becom               becom               becomes            \n",
            "prototype           prototyp            prototyp            prototype          \n",
            "ideas               idea                idea                idea               \n",
            "spark               spark               spark               spark              \n",
            "global              global              glob                global             \n",
            "change              chang               chang               change             \n"
          ]
        }
      ],
      "source": [
        "print(f\"{'Original':<19} {'Porter':<19} {'Lancaster':<19} {'Lemma':<19}\")\n",
        "print(\"-\" * 60)\n",
        "for o, p, l, le in zip(stopper_removed, portered, lancastered, lemmatized):\n",
        "    print(\"{:<19} {:<19} {:<19} {:<19}\".format(o, p, l, le))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "49f3f33a-5e64-4d4b-8ae4-6ce4e8665250",
      "metadata": {
        "id": "49f3f33a-5e64-4d4b-8ae4-6ce4e8665250"
      },
      "source": [
        "# Question 3. Regular Expressions and Text Spliƫng\n",
        "1. Take their original text from Question 1.\n",
        "2. Use regular expressions to:\n",
        "\n",
        "    - a. Extract all words with more than 5 letters.\n",
        "\n",
        "    - b. Extract all numbers (if any exist in their text).\n",
        "\n",
        "    - c. Extract all capitalized words.\n",
        "3. Use text spliƫng techniques to:\n",
        "   \n",
        "    - a. Split the text into words containing only alphabets (removing digits and specialcharacters).\n",
        "    - b. Extract words starting with a vowel."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "9c9b492d-7dfb-492d-9182-135ac4aedc5b",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9c9b492d-7dfb-492d-9182-135ac4aedc5b",
        "outputId": "cfcb67ad-b7c0-4270-fc5c-5ba482c06177"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "words (>5) letters:   ['interests', 'technology', 'captivates', 'especially', 'reshaping', 'interaction', 'creativity', 'transformed', 'imagine', 'future', 'blurring', 'between', 'machine', 'development', 'computing', 'particularly', 'fascinating', 'enables', 'realtime', 'processing', 'generated', 'reducing', 'latency', 'empowering', 'smarter', 'systems', 'hardware', 'breakthrough', 'processors', 'neuromorphic', 'closer', 'mimicking', 'cognition', 'excites', 'potential', 'democratizing', 'innovation', 'giving', 'creators', 'reserved', 'corporations', 'thrilling', 'imagination', 'quickly', 'becomes', 'prototype', 'global', 'change'] \n",
            "\n",
            "\n",
            "Numbers :   [] \n",
            "\n",
            "\n",
            "Capitalized :   ['Among', 'The', 'AI', 'I', 'IoT', 'Every', 'RISC', 'V', 'What', 'It'] \n",
            "\n",
            "\n",
            "Only alpha words:   ['among', 'all', 'my', 'interests', 'technology', 'captivates', 'me', 'the', 'most', 'especially', 'how', 'its', 'reshaping', 'human', 'interaction', 'and', 'creativity', 'the', 'rise', 'of', 'ai', 'has', 'transformed', 'the', 'way', 'we', 'write', 'code', 'and', 'even', 'imagine', 'the', 'future', 'blurring', 'the', 'lines', 'between', 'human', 'and', 'machine', 'i', 'find', 'the', 'development', 'of', 'edge', 'computing', 'particularly', 'fascinating', 'as', 'it', 'enables', 'realtime', 'data', 'processing', 'right', 'where', 'it', 's', 'generated', 'reducing', 'latency', 'and', 'empowering', 'smarter', 'iot', 'systems', 'every', 'new', 'hardware', 'breakthrough', 'like', 'riscv', 'processors', 'or', 'neuromorphic', 'chips', 'feels', 'like', 'a', 'small', 'step', 'closer', 'to', 'mimicking', 'human', 'cognition', 'what', 'excites', 'me', 'most', 'is', 'the', 'potential', 'for', 'democratizing', 'innovation', 'giving', 'even', 'small', 'creators', 'the', 'tools', 'once', 'reserved', 'for', 'large', 'corporations', 'its', 'a', 'thrilling', 'time', 'to', 'be', 'alive', 'where', 'imagination', 'quickly', 'becomes', 'prototype', 'and', 'ideas', 'can', 'spark', 'global', 'change'] \n",
            "\n",
            "Only alpha words:\n",
            " ['among', 'all', 'my', 'interests', 'technology', 'captivates', 'me', 'the', 'how', 'its', 'reshaping', 'human', 'interaction', 'and', 'creativity', 'the', 'rise', 'of', 'ai', 'has', 'transformed', 'the', 'way', 'we', 'write', 'code', 'and', 'even', 'imagine', 'the', 'future', 'blurring', 'the', 'lines', 'between', 'human', 'and', 'machine', 'i', 'find', 'the', 'development', 'of', 'edge', 'computing', 'particularly', 'fascinating', 'as', 'it', 'enables', 'realtime', 'data', 'processing', 'right', 'where', 'generated', 'reducing', 'latency', 'and', 'empowering', 'smarter', 'iot', 'systems', 'every', 'new', 'hardware', 'breakthrough', 'like', 'riscv', 'processors', 'or', 'neuromorphic', 'chips', 'feels', 'like', 'a', 'small', 'step', 'closer', 'to', 'mimicking', 'human', 'cognition', 'what', 'excites', 'me', 'most', 'is', 'the', 'potential', 'for', 'democratizing', 'innovation', 'giving', 'even', 'small', 'creators', 'the', 'tools', 'once', 'reserved', 'for', 'large', 'corporations', 'its', 'a', 'thrilling', 'time', 'to', 'be', 'imagination', 'quickly', 'becomes', 'prototype', 'and', 'ideas', 'can', 'spark', 'global', 'change']\n",
            "\n",
            "Words starting with vowels:\n",
            " ['among', 'all', 'interests', 'especially', 'its', 'interaction', 'and', 'of', 'ai', 'and', 'even', 'imagine', 'and', 'i', 'of', 'edge', 'as', 'it', 'enables', 'it', 'and', 'empowering', 'iot', 'every', 'or', 'a', 'excites', 'is', 'innovation', 'even', 'once', 'its', 'a', 'alive', 'imagination', 'and', 'ideas']\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "letter_5 = re.findall(r'\\b\\w{6,}\\b', no_punc)\n",
        "print(\"words (>5) letters:  \", letter_5 ,'\\n')\n",
        "# \\w{6,} = Match any word (\\w) with 6 or more characters.\n",
        "\n",
        "numb = re.findall(r'\\b\\d+\\b', no_punc)\n",
        "print(\"\\nNumbers :  \", numb,'\\n')\n",
        "# \\d+ = One or more digits (0-9)\n",
        "\n",
        "caps = re.findall(r'\\b[A-Z][a-zA-Z]*\\b', sentence)\n",
        "print(\"\\nCapitalized :  \", caps, '\\n')\n",
        "# [a-zA-Z]* = Followed by zero or more letters (upper/lower case).\n",
        "\n",
        "alphas = re.findall(r'\\b[a-zA-Z]+\\b', no_punc)\n",
        "print(\"\\nOnly alpha words:  \", alphas, '\\n')\n",
        "# [a-zA-Z]+ = One or more alphabet characters (no digits or symbols).\n",
        "\n",
        "# text into words\n",
        "words_list = no_punc.split()\n",
        "only_alpha_words = [w for w in words_list if w.isalpha()]\n",
        "print(\"Only alpha words:\\n\", only_alpha_words)\n",
        "\n",
        "vowelss = [w for w in alphas if w[0].lower() in 'aeiou']\n",
        "print(\"\\nWords starting with vowels:\\n\", vowelss)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "385a84f3-f396-475f-ab62-cdf9f3ea6ed7",
      "metadata": {
        "id": "385a84f3-f396-475f-ab62-cdf9f3ea6ed7"
      },
      "source": [
        "# Q4. Custom Tokenization & Regex-based Text Cleaning\n",
        "\n",
        "## Steps:\n",
        "\n",
        "1. **Input**: Use the original text from **Question 1**.\n",
        "\n",
        "2. **Custom Tokenization Function Requirements**:\n",
        "   \n",
        "   - **(a)** Remove punctuation and special symbols, **but keep contractions** (e.g., `\"isn't\"` should remain `\"isn't\"` and not split into `\"is\"` and `\"n't\"`).\n",
        "   \n",
        "   - **(b)** Handle **hyphenated words** as **single tokens** (e.g., `\"state-of-the-art\"` should remain as one token).\n",
        "   \n",
        "   - **(c)** **Tokenize numbers separately**, but **keep decimal numbers intact** (e.g., `\"3.14\"` should remain `\"3.14\"`).\n",
        "\n",
        "3. **Regex Substitutions** (using `re.sub`):\n",
        "\n",
        "   - **(a)** Replace **email addresses** with the placeholder `<EMAIL>`.\n",
        "   \n",
        "   - **(b)** Replace **URLs** with the placeholder `<URL>`.\n",
        "   \n",
        "   - **(c)** Replace **phone numbers** (formats like `123-456-7890` or `+91 9876543210`) with the plceho-z0-9.-]+\\.[A-Z|a-z]{2,}\\b\n",
        "placeholder."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "1ba0f752-0f2b-4d70-b76d-b5b16fd6cc2a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ba0f752-0f2b-4d70-b76d-b5b16fd6cc2a",
        "outputId": "249c1ac2-a7ae-4052-eb75-ebdc2cc8ac20"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Custom Tokens:   ['Among', 'all', 'my', 'interests', 'technology', 'captivates', 'me', 'the', 'mostespecially', 'how', \"it's\", 'reshaping', 'human', 'interaction', 'and', 'creativity', 'The', 'rise', 'of', 'AI', 'has', 'transformed', 'the', 'way', 'we', 'write', 'code', 'and', 'even', 'imagine', 'the', 'future', 'blurring', 'the', 'lines', 'between', 'human', 'and', 'machine', 'I', 'find', 'the', 'development', 'of', 'edge', 'computing', 'particularly', 'fascinating', 'as', 'it', 'enables', 'real-time', 'data', 'processing', 'right', 'where', 'its', 'generated', 'reducing', 'latency', 'and', 'empowering', 'smarter', 'IoT', 'systems', 'Every', 'new', 'hardware', 'breakthrough', 'like', 'RISC-V', 'processors', 'or', 'neuromorphic', 'chips', 'feels', 'like', 'a', 'small', 'step', 'closer', 'to', 'mimicking', 'human', 'cognition', 'What', 'excites', 'me', 'most', 'is', 'the', 'potential', 'for', 'democratizing', 'innovation', 'giving', 'even', 'small', 'creators', 'the', 'tools', 'once', 'reserved', 'for', 'large', 'corporations', \"It's\", 'a', 'thrilling', 'time', 'to', 'be', 'alivewhere', 'imagination', 'quickly', 'becomes', 'prototype', 'and', 'ideas', 'can', 'spark', 'global', 'change'] \n",
            "\n",
            "\n",
            "Text after Regex Substitutions:\n",
            " \n",
            "Among all my interests, technology captivates me the most—especially how it's reshaping human interaction and creativity. \n",
            "The rise of AI has transformed the way we write, code, and even imagine the future, blurring the lines between human and machine. \n",
            "I find the development of edge computing particularly fascinating, as it enables real-time data processing right where it’s generated, reducing latency and empowering smarter IoT systems. \n",
            "Every new hardware breakthrough, like RISC-V processors or neuromorphic chips, feels like a small step closer to mimicking human cognition. \n",
            "What excites me most is the potential for democratizing innovation, giving even small creators the tools once reserved for large corporations. \n",
            "It's a thrilling time to be alive—where imagination quickly becomes prototype, and ideas can spark global change.\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Custom Tokenizer\n",
        "def custom_tokens(text):\n",
        "    text = re.sub(r\"[^a-zA-Z0-9\\s\\-']\", \"\", text)\n",
        "    tokens = re.findall(r\"\\b\\w+(?:[-']\\w+)*\\b\", text)\n",
        "    # ?: = Non-capturing group (just groups the pattern, doesn't save it separately)\n",
        "    return tokens\n",
        "customs = custom_tokens(sentence)\n",
        "print(\"\\nCustom Tokens:  \", customs, '\\n')\n",
        "\n",
        "\n",
        "text_replaced = re.sub(r'\\b[\\w.-]+?@\\w+?\\.\\w+?\\b', '<EMAIL>', sentence)\n",
        "# [\\w.-]+?\tOne or more word characters (a-z, A-Z, 0-9, _), dot ., or hyphen - (email username part)\n",
        "# \\w+?\tDomain name (like gmail) and then the domain extension\n",
        "\n",
        "text_replaced = re.sub(r'http[s]?://\\S+', '<URL>', text_replaced)\n",
        "# http[s]?\tMatch http or https (the s? means \"s\" is optional)\n",
        "# \\S+\tMatch one or more non-space characters (the URL itself)\n",
        "\n",
        "text_replaced = re.sub(r'(\\+?\\d{1,2}\\s?)?(\\d{3}[-\\s]?\\d{3}[-\\s]?\\d{4})', '<PHONE>', text_replaced)\n",
        "# (\\+?\\d{1,2}\\s?)? – The entire pattern is optional due to the outer ()\n",
        "# \\+?  Matches an optional plus sign (+)\n",
        "# \\d{1,2}  Matches 1 or 2 digits (0-9)\n",
        "# \\s?   Matches an optional whitespace character (like a space or tab)\n",
        "# [-\\s]?   Optional hyphen or space (separator)\n",
        "# \\d{4}\tExactly 4 digits (last part)\n",
        "print(\"\\nText after Regex Substitutions:\\n\", text_replaced)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4a6d4c7e-1fef-4ce9-ae77-e8e8b93897e2",
      "metadata": {
        "id": "4a6d4c7e-1fef-4ce9-ae77-e8e8b93897e2"
      },
      "outputs": [],
      "source": [
        "\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}